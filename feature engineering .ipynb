{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80bf8584-3177-4991-85b5-d413b9ba2cc5",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e9c296-7398-4a44-8fda-6751bb822461",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Asssignment Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05911af9-2384-40b2-a3c3-c7cd77c6f64f",
   "metadata": {},
   "source": [
    "## 1.What is a parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616bb9f9-8c3f-4cf5-99e3-e5624998dd44",
   "metadata": {},
   "source": [
    "### A parameter is a value inside a model that influences how the model makes predictions. These values are not set manually ‚Äî the algorithm automatically adjusts them to fit the data better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8445ae4-6a2c-42db-9cab-5286c83d8445",
   "metadata": {},
   "source": [
    "### üß† Examples:\n",
    "1. Linear Regression\n",
    "Model:\n",
    "\n",
    "   y=wx+b\n",
    "\n",
    "- w (weight) and b (bias) are parameters.\n",
    "- During training, the algorithm adjusts w and b to minimize the prediction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339de40b-4eac-402b-bda5-69dd85ee6fab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1da587bd-a78a-4219-9ce2-75fd95fe31eb",
   "metadata": {},
   "source": [
    "## 2.What is correlation? What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee32b1d-553f-4e94-9fc3-012b599c0d2f",
   "metadata": {},
   "source": [
    "### Correlation measures the relationship between two variables ‚Äî how they move together.\n",
    "\n",
    "- It ranges from -1 to +1.\n",
    "  - +1: Perfect positive correlation (both go up together)\n",
    "  - 0: No correlation\n",
    "  - -1: Perfect negative correlation (one goes up, the other goes down)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b518f6b6-ee58-4dd2-8b32-d5d0ca6c3577",
   "metadata": {
    "tags": []
   },
   "source": [
    "### üîª What is Negative Correlation?\n",
    "- Negative correlation means:\n",
    "- When one variable increases, the other decreases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3b7432-23b2-4da6-b75d-871807019aad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eccd4d5-0f79-426d-943a-3f641b81068b",
   "metadata": {},
   "source": [
    "## 3.Define Machine learning. What are the main components in machine learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7000cb0d-bafc-4f03-b4a4-3bcb2c7090b8",
   "metadata": {},
   "source": [
    "### Machine Learning (ML) is a branch of Artificial Intelligence where computers learn patterns from data and make decisions or predictions without being explicitly programmed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a72cb34-d6e7-41f1-9d56-113b0a562c21",
   "metadata": {},
   "source": [
    "üß© Main Components in Machine Learning:\n",
    "- 1.Data\n",
    "   - Raw information used to train and test the model.\n",
    "   - Example: customer age, income, product ratings.\n",
    "\n",
    "- 2.Model\n",
    "   - The mathematical structure that learns from data and makes predictions.\n",
    "   - Example: Linear Regression, Decision Tree.\n",
    "\n",
    "- 3.Algorithm\n",
    "   - The method or process used to train the model.\n",
    "   - Example: Gradient Descent, k-NN, Random Forest algorithm.\n",
    "\n",
    "- 4.Loss Function\n",
    "   - Measures how far the model‚Äôs prediction is from the actual value.\n",
    "   - Example: Mean Squared Error (MSE).\n",
    "\n",
    "- 4.Training\n",
    "   - The process of feeding data into the model to learn patterns and adjust parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e795c9-6bdf-44c5-9e9b-dbf9b3dee929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "06ce21a3-100a-4c4a-80af-a3dd6ee6a827",
   "metadata": {},
   "source": [
    "## 4.How does loss value help in determining whether the model is good or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c01e21e-3cae-4ffa-85b2-ff019ac80854",
   "metadata": {},
   "source": [
    "### The loss value tells us how far off the model‚Äôs predictions are from the actual values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2864477-1f5b-471a-9d14-348b153e5908",
   "metadata": {},
   "source": [
    "- Low loss = Model predictions are close to the actual values ‚Üí ‚úÖ Good model\n",
    "- High loss = Model predictions are far off ‚Üí ‚ùå Poor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52e2600-78fc-45cf-a196-416f9bfc4415",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b55cd159-1ff6-486d-9864-403fdd01107e",
   "metadata": {},
   "source": [
    "## 5.What are continous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c286347-9810-4894-b5c7-83c86fd554ec",
   "metadata": {},
   "source": [
    "### üî¢ Continuous Variables\n",
    "- Variables that can take any numeric value within a range.\n",
    "- They are measurable.\n",
    "\n",
    "Examples:\n",
    "- Height (e.g., 172.5 cm)\n",
    "- Temperature (e.g., 36.7¬∞C)\n",
    "- Salary (e.g., ‚Çπ45,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d35d93a-8999-476e-95af-bf931f6c816d",
   "metadata": {},
   "source": [
    "### üî† Categorical Variables\n",
    "- Variables that represent groups or categories.\n",
    "- They are not numeric (or are treated as labels).\n",
    "\n",
    "Examples:\n",
    "- Gender (Male, Female)\n",
    "- Color (Red, Blue, Green)\n",
    "- City (Delhi, Mumbai, Chennai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa8bd21-34e1-4a66-945a-190dae83959b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f323618e-2901-40d3-9259-d086d5952345",
   "metadata": {},
   "source": [
    "## 6. How do we handle categorical variables in machine learning? What are the common techniques?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166f6d0d-b64a-4064-902a-4480fb7738d8",
   "metadata": {},
   "source": [
    "### 1. Label Encoding\n",
    "- Converts each category into a unique number.\n",
    "- Example:\n",
    "Color = [Red, Green, Blue] ‚Üí Red=0, Green=1, Blue=2\n",
    "- ‚úÖ Simple\n",
    "- ‚ö†Ô∏è May create a false order (not suitable for non-ordinal categories)\n",
    "\n",
    "### 2. One-Hot Encoding\n",
    "- Creates a new column for each category with 0 or 1.\n",
    "- Example:\n",
    "  Color = Red ‚Üí [1, 0, 0]\n",
    "  Color = Blue ‚Üí [0, 0, 1]\n",
    "- ‚úÖ No false order\n",
    "- ‚ö†Ô∏è Increases data size if many categories\n",
    "\n",
    "### 3. Ordinal Encoding\n",
    "- Used when categories have a natural order.\n",
    "- Example:\n",
    "  Size = [Small, Medium, Large] ‚Üí Small=1, Medium=2, Large=3\n",
    "\n",
    "### 4. Binary Encoding / Target Encoding / Frequency Encoding\n",
    "- Advanced techniques used when dealing with high-cardinality data (many unique values).\n",
    "- Example: Encoding based on how often each category appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86799f59-1ff9-4a2e-b839-598aec19f2fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c26cf6f1-b10d-4a06-be64-7e4430438128",
   "metadata": {},
   "source": [
    "## 7.What do you mean by training and testing a dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6fe38-d117-44ee-a3eb-a69a00641e3f",
   "metadata": {},
   "source": [
    "### üìö Training Dataset\n",
    "- This is the data used to teach the model.\n",
    "- The model learns patterns from this data.\n",
    "- Contains both inputs (features) and outputs (labels).\n",
    "\n",
    "### üß™ Testing Dataset\n",
    "- This is the data used to check how well the model performs.\n",
    "- It is never shown to the model during training.\n",
    "- Helps us measure accuracy, precision, etc., on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2700ec9d-5525-46e3-8af7-5120b8ea142b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7f2d485-5592-48e0-835b-760825258e84",
   "metadata": {},
   "source": [
    "## 8.What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebebb74-361a-4ed3-8847-d18261a3258c",
   "metadata": {},
   "source": [
    "### Real-world data is often unclean or unfit for direct use in ML models.\n",
    "### sklearn.preprocessing helps in scaling, encoding, and transforming features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c4e0f-8956-4523-8b4c-d3bca1d58a9d",
   "metadata": {},
   "source": [
    "| Function               | What It Does                                 | Example Use                  |\n",
    "| ---------------------- | -------------------------------------------- | ---------------------------- |\n",
    "| `StandardScaler()`     | Standardizes features (mean = 0, std = 1)    | For algorithms like SVM      |\n",
    "| `MinMaxScaler()`       | Scales features to a range (e.g., 0 to 1)    | For neural networks          |\n",
    "| `LabelEncoder()`       | Converts labels to numbers                   | Encode class labels          |\n",
    "| `OneHotEncoder()`      | Converts categories to binary vectors        | For nominal categorical data |\n",
    "| `Binarizer()`          | Converts values to 0 or 1 based on threshold | For binary classification    |\n",
    "| `PolynomialFeatures()` | Adds interaction/power terms                 | For non-linear models        |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f782a131-22e5-4a90-bdd8-27cf7669256a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "63aa2ade-89a7-49a1-93ef-1a8b1f9a6022",
   "metadata": {},
   "source": [
    "## 9. What is a test set?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8557158-5b7b-4291-a52b-8a1720940f72",
   "metadata": {},
   "source": [
    "### A test set is a portion of the dataset that is used to evaluate the performance of a trained machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3818a377-d071-4b8c-9ac5-1eed7ada461c",
   "metadata": {},
   "source": [
    "### üß† Example:\n",
    "If you have 1000 rows of data:\n",
    " - Training set: 80% (800 rows) ‚Üí used to train the model\n",
    " - Test set: 20% (200 rows) ‚Üí used to test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4550967-97d8-4b99-84d4-feac7d352eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "09639b16-e374-4a11-9709-25a79ca0c138",
   "metadata": {},
   "source": [
    "## 10.How do we split data for model fitting(training and testing) in python? how do you approach a machine learning problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117568e-d182-46ef-9ae6-477e6718917e",
   "metadata": {},
   "source": [
    "### üß™ Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adb4000-872a-44b0-bd9b-d5cfda200170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = features, y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2b7ee0-8aec-4ad5-9976-f52039351ce4",
   "metadata": {},
   "source": [
    "### üß† How Do You Approach a Machine Learning Problem?\n",
    "ü™ú Step-by-Step Approach:\n",
    "1.Understand the Problem\n",
    "  - What is being predicted? (classification, regression, etc.)\n",
    "  - What is the goal?\n",
    "\n",
    "2.Collect Data\n",
    "  - From CSV, databases, APIs, etc.\n",
    "\n",
    "3.Explore and Clean Data\n",
    "  - Handle missing values, duplicates, incorrect types\n",
    "  - Understand data distributions (EDA)\n",
    "\n",
    "4.Preprocess Data\n",
    "  - Encode categorical variables (Label/One-Hot)\n",
    "  - Scale numerical features\n",
    "  - Split into training and test sets\n",
    "\n",
    "5.Choose a Model\n",
    "  - Linear Regression, Decision Tree, SVM, etc., depending on the problem\n",
    "\n",
    "6.Train the Model\n",
    "  - Use training data to fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361b2a57-0668-476a-856a-ac85b1b04034",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cd64abb9-db44-4f02-8f23-0c7b33e4bcb6",
   "metadata": {},
   "source": [
    "## 11.Why do we have to perform EDA before fitting a model to the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ddc88-4ad8-4b51-aa7a-fe34f7498d1e",
   "metadata": {},
   "source": [
    "### EDA is the process of exploring and understanding the dataset using statistics and visualizations before applying machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6612b936-60c1-4d84-9369-041655822d1c",
   "metadata": {},
   "source": [
    "1.Understand the Data\n",
    "  - Know what features (columns) exist\n",
    "  - Check data types (numerical, categorical)\n",
    "\n",
    "2.Find Missing or Incorrect Data\n",
    "  - Identify and handle missing values, outliers, or wrong entries\n",
    "\n",
    "3.Detect Patterns and Relationships\n",
    "  - Spot useful trends and correlations\n",
    "  - Helps in selecting meaningful features\n",
    "\n",
    "4.Feature Selection & Engineering\n",
    "  - Decide which features to keep, combine, or transform\n",
    "\n",
    "5.Choose the Right Model\n",
    "  - Based on the type of data (e.g., linear vs. non-linear patterns)\n",
    "\n",
    "6.Improve Model Accuracy\n",
    "  - Clean, well-understood data leads to better training and predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dd60e9-a200-4a33-9c14-f837bfda0c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "856ffac1-77c0-4c12-a08d-d14b6b20a8e5",
   "metadata": {},
   "source": [
    "## 12.What is correlation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ee1ba-eae2-4da0-809c-5d2f96ec6028",
   "metadata": {},
   "source": [
    "### Correlation is a statistical measure that shows the relationship between two variables ‚Äî how they change together."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604e1884-7214-4c93-a1ad-239471244027",
   "metadata": {},
   "source": [
    "üîÅ Types of Correlation:\n",
    "- Positive correlation:\n",
    "  As one variable increases, the other also increases.\n",
    "  üëâ Example: Height and weight\n",
    "\n",
    "- Negative correlation:\n",
    "  As one variable increases, the other decreases.\n",
    "  üëâ Example: Speed and travel time\n",
    "\n",
    "- Zero correlation:\n",
    "  No relationship between the variables.\n",
    "  üëâ Example: Shoe size and intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee01d18-9abf-4565-b0e4-045ba2746a6a",
   "metadata": {},
   "source": [
    "### range of correlation coefficient(r):\n",
    "   -1<=r<=+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107c2434-b76f-4b83-a738-3d2f550ff2ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e90ffde3-6fa6-44a6-8bac-b29c2004c548",
   "metadata": {},
   "source": [
    "## 13.What does negative correlation mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53458a-d200-4356-b020-35780a661caf",
   "metadata": {},
   "source": [
    "### Negative correlation means that when one variable increases, the other decreases ‚Äî they move in opposite directions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c67175-4356-44b5-9a62-a561e3dc9018",
   "metadata": {},
   "source": [
    "### üî¢ Correlation Coefficient Range:\n",
    "- Negative correlation values range from 0 to -1:\n",
    "  - -1 ‚Üí perfect negative correlation\n",
    "  - -0.5 ‚Üí moderate negative correlation\n",
    "  - 0 ‚Üí no correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f601982-c8c2-4a4f-8912-4cac9612fed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4da21cd3-ca5e-4a9c-8a40-7c7fa39f5fbe",
   "metadata": {},
   "source": [
    "## 14.How can you find correlation between variables in python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d8c53de-5e50-4839-9f32-cfb43b512154",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Age    Salary  Experience\n",
      "Age         1.000000  1.000000    0.997054\n",
      "Salary      1.000000  1.000000    0.997054\n",
      "Experience  0.997054  0.997054    1.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample DataFrame\n",
    "data = {\n",
    "    'Age': [25, 30, 35, 40],\n",
    "    'Salary': [40000, 50000, 60000, 70000],\n",
    "    'Experience': [2, 5, 7, 10]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Correlation matrix\n",
    "correlation_matrix = df.corr()\n",
    "print(correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3f6e0a-4255-4845-9aa1-ef8002d90df1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9eb8d07f-c767-495c-9a2b-8703e085c8f4",
   "metadata": {},
   "source": [
    "## 15.What is causation? explain difference between correlation and causation with an example?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22d2ed6-df57-4697-9e39-4e4d0b61bf94",
   "metadata": {},
   "source": [
    "| Aspect    | **Correlation**         | **Causation**                           |\n",
    "| --------- | ----------------------- | --------------------------------------- |\n",
    "| Meaning   | Variables move together | One variable directly affects the other |\n",
    "| Direction | No direction implied    | Has a clear cause-effect direction      |\n",
    "| Proof     | Easy to calculate       | Harder to prove                         |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fe45b-3db7-4130-b7f3-f261bc1fae67",
   "metadata": {},
   "source": [
    "### üß† Example:\n",
    "‚úÖ Correlation (but not causation):\n",
    "  - Ice cream sales and drowning incidents both increase in summer.\n",
    "  - They are positively correlated, but ice cream doesn't cause drowning.\n",
    "\n",
    "‚úÖ Causation:\n",
    "  - Smoking causes lung disease.\n",
    "  - Proven by experiments and studies ‚Äî it's a cause-effect relationship."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840ceabe-3453-4166-b5fb-a4e91416517d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16c0a64c-2877-41c9-8e79-b61fc885acfb",
   "metadata": {},
   "source": [
    "## 16.What is an optimizer? What are different types of optimizers? Explain each with an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc94c8a-4685-4737-9e6a-c181aa246b14",
   "metadata": {},
   "source": [
    "### An optimizer is an algorithm that adjusts the model‚Äôs parameters (like weights and biases) during training to minimize the loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b85d92-43e6-46db-b397-1680e9136b6c",
   "metadata": {},
   "source": [
    "### Types of optimizers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d34c6f84-f50a-49f4-981c-1828c87b137d",
   "metadata": {},
   "source": [
    "### 1. Gradient Descent (GD)\n",
    "- Basic optimizer that uses the full dataset to compute gradients.\n",
    "- Updates parameters in the opposite direction of the gradient of the loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f0d073-4741-4853-a48a-1f0f0bdc9709",
   "metadata": {},
   "source": [
    "### 2. Stochastic Gradient Descent (SGD)\n",
    "- Uses only one data point at a time to update parameters.\n",
    "- Faster but can be noisy (fluctuates more)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336212dc-2eb8-4ad5-8596-3bea9355a857",
   "metadata": {},
   "source": [
    "### 3. Mini-Batch Gradient Descent\n",
    "- Compromise between GD and SGD.\n",
    "- Uses a small batch of data (e.g., 32 or 64 samples) at a time.\n",
    "- Most commonly used in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c9670cb-8b20-4c58-8870-726e8a888ce1",
   "metadata": {},
   "source": [
    "### 4. Adam (Adaptive Moment Estimation)\n",
    "  - Combines the best of Momentum and RMSprop.\n",
    "  - Maintains moving averages of gradients and their squares.\n",
    "  - Fast, efficient, and handles sparse data well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d951eb-6fe7-4e4c-88b9-196ec02a7bee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e779fe94-368e-4421-a5cd-29fbfe14d843",
   "metadata": {},
   "source": [
    "## 17.What is sklearn.linear_model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10117fb-5ab0-432c-9d65-adf00fee3594",
   "metadata": {},
   "source": [
    "### sklearn.linear_model is a module in Scikit-learn that provides linear models for both regression and classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13cf968-e86f-4782-8777-571a465149d7",
   "metadata": {},
   "source": [
    "### üß† What are Linear Models?\n",
    "Linear models make predictions using a linear relationship between input features and the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbb460f-3f94-41e4-b8bb-e558ef4770bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ef552a3-e4b1-429f-bd00-035824e504bc",
   "metadata": {},
   "source": [
    "### 18.What does model.fit() do? What argument must be given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a733b896-ea4b-4272-b960-04cc26e90373",
   "metadata": {},
   "source": [
    "model.fit() is the function that trains your machine learning model using the given data.\n",
    "\n",
    "It learns patterns from the training data by adjusting the model‚Äôs parameters (like weights).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73da2a95-ee78-42f5-8ea4-28b1901f8933",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3430462-c191-4048-bce0-88bf6dd332f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07680c2d-62d0-4929-a112-ff93fd972a4d",
   "metadata": {},
   "source": [
    "## 19.What does model.predict() do? What arguments must be given?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81bd9f6-3f23-4692-bbb9-243366b56dbc",
   "metadata": {},
   "source": [
    "### model.predict() is used to make predictions using a trained machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3adc7cb8-cdb4-4a18-bc4d-3e54d1517bab",
   "metadata": {},
   "source": [
    "### It takes input features and returns the model‚Äôs predicted outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1c9d78-7323-48fd-afc3-5b66b56c343d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f05d09b7-3670-4f1d-8cb2-635aae1997e4",
   "metadata": {},
   "source": [
    "## 20.What are continous and categorical variables?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40346408-503e-4808-bd6b-961611899a5e",
   "metadata": {},
   "source": [
    "üî¢ Continuous Variables:\n",
    "- Can take any numeric value within a range (including decimals).\n",
    "- They are measurable quantities.\n",
    "\n",
    "üìå Examples:\n",
    "- Age (e.g., 25.6 years)\n",
    "- Temperature (e.g., 37.2¬∞C)\n",
    "- Salary (e.g., ‚Çπ45,000.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eaada7e-7522-4f8d-a29f-7cf2ae86ef72",
   "metadata": {
    "tags": []
   },
   "source": [
    "üî† Categorical Variables:\n",
    "- Represent groups or categories.\n",
    "- Can be labels or names, not numeric by nature.\n",
    "- Often need to be encoded before using in ML models.\n",
    "\n",
    "üìå Examples:\n",
    "- Gender (Male, Female)\n",
    "- Color (Red, Blue, Green)\n",
    "- Country (India, USA, Japan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195eba06-d660-4737-91dc-cfa79812090d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ee15b26-0f26-4ae9-848c-77c0ae617066",
   "metadata": {},
   "source": [
    "## 21.What is feature scaling? how does it help in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00478044-5501-4725-82c7-625324eb86b9",
   "metadata": {},
   "source": [
    "### Feature Scaling is the process of normalizing or standardizing the range of features (input variables) in your dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d596b544-3d9e-4cba-ad53-5f3e0ce24143",
   "metadata": {},
   "source": [
    "üöÄ How It Helps in ML:\n",
    "- Improves model performance and convergence speed.\n",
    "- Ensures fair treatment of all features.\n",
    "- Prevents bias toward features with large values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fa2099-24b9-4620-991a-df4e4d2b6083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fca11e26-a595-4fa5-8e28-68d3dbcafed1",
   "metadata": {},
   "source": [
    "## 22.How do we perform scaling in python? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839db6b-b176-411e-bb01-60a5f862af36",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è 1. Standardization (Mean = 0, Std = 1)\n",
    "### üõ†Ô∏è 2. Normalization (Scale between 0 and 1)\n",
    "### üõ†Ô∏è 3. Robust Scaling (Uses median and IQR, good for outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb341c-8630-409f-b113-e1a61b0e6795",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4d665489-f6ff-4a04-8d49-39fcd4c101f2",
   "metadata": {},
   "source": [
    "## 23. What is sklearn.preprocessing?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96112b0f-1d3b-463b-b74f-c315ca054ba4",
   "metadata": {},
   "source": [
    "### sklearn.preprocessing is a module in Scikit-learn that provides tools to prepare and transform raw data before training a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5901a7fc-2dc2-4e48-a886-42389c7f0461",
   "metadata": {},
   "source": [
    "### üß∞ Common Functions in sklearn.preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fcf46c-086e-4572-8697-9875e8318cea",
   "metadata": {},
   "source": [
    "| Function/Class         | What It Does                                   | Example Use                    |\n",
    "| ---------------------- | ---------------------------------------------- | ------------------------------ |\n",
    "| `StandardScaler()`     | Standardizes features (mean = 0, std = 1)      | For algorithms like SVM, LR    |\n",
    "| `MinMaxScaler()`       | Scales features between 0 and 1                | For neural networks            |\n",
    "| `LabelEncoder()`       | Converts labels (target) to numbers            | For classification tasks       |\n",
    "| `OneHotEncoder()`      | Converts categorical variables to binary       | For categorical input features |\n",
    "| `Binarizer()`          | Converts values to 0 or 1                      | For binary thresholding        |\n",
    "| `PolynomialFeatures()` | Creates polynomial and interaction terms       | For non-linear relationships   |\n",
    "| `RobustScaler()`       | Scales using median and IQR (handles outliers) | When data has outliers         |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f549cdc6-49f7-4356-857f-c7be99464a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00fb3cf6-f31b-42b2-ad8d-4d271d350d86",
   "metadata": {},
   "source": [
    "## 24.How do we split data for model fitting(training and testing) in python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaefa684-c3fe-4ee8-9c5c-4dae3ea9f84f",
   "metadata": {},
   "source": [
    "### We use train_test_split() from sklearn.model_selection to divide the data into training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864e252-380b-4883-a194-7b04208eb400",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X = features, y = target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad2676-a90c-48e3-b1e2-66d41fb94cc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cad92854-9f60-4a59-b31a-0d68aa806b92",
   "metadata": {},
   "source": [
    "## 25.Explain data encoding?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87fb231-f3f3-4b50-ad3c-46446d4c23ec",
   "metadata": {},
   "source": [
    "### Data encoding is the process of converting categorical (non-numeric) data into numeric format so that it can be used by machine learning models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2673d6-c70a-4ce9-a63c-9b0e3b76a893",
   "metadata": {},
   "source": [
    "### üéØ Why Encoding is Needed:\n",
    "- Categorical data like [\"Red\", \"Green\", \"Blue\"] can‚Äôt be processed directly.\n",
    "- Encoding converts these into numbers or vectors that models can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a8c256-5f3f-4953-b2d6-5ff4d7321022",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
